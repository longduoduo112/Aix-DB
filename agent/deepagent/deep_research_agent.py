"""
Deep Research Agent - åŸºäº DeepAgents çš„ Text-to-SQL æ™ºèƒ½ä½“

é‡æ„è¯´æ˜ï¼š
1. ä½¿ç”¨ä¼šè¯çº§å·¥å…·è°ƒç”¨ç®¡ç†å™¨ï¼Œè§£å†³æ­»å¾ªç¯é—®é¢˜
2. é™ä½ recursion_limitï¼Œæ·»åŠ æ—©æœŸç»ˆæ­¢æœºåˆ¶
3. æ·»åŠ åˆ†æ­¥è¶…æ—¶æ§åˆ¶ï¼Œè§£å†³ä»»åŠ¡è¶…æ—¶é—®é¢˜
4. å¢å¼ºè¿›åº¦è¿½è¸ªå’ŒçŠ¶æ€ç›‘æ§
"""

import asyncio
import json
import logging
import os
import time
import traceback
import uuid
from typing import Optional

from deepagents import create_deep_agent
from deepagents.backends import FilesystemBackend
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.utilities import SQLDatabase
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
from langgraph.checkpoint.memory import InMemorySaver

from agent.deepagent.tools.native_sql_tools import (
    set_native_datasource_info,
    sql_db_list_tables,
    sql_db_query,
    sql_db_query_checker,
    sql_db_schema,
    sql_db_table_relationship,
)
from agent.deepagent.tools.tool_call_manager import (
    get_tool_call_manager,
    set_current_session,
)
from common.datasource_util import (
    DB,
    ConnectType,
    DatasourceConfigUtil,
    DatasourceConnectionUtil,
)
from common.llm_util import get_llm
from constants.code_enum import DataTypeEnum, IntentEnum
from model.db_connection_pool import get_db_pool
from services.datasource_service import DatasourceService
from services.user_service import add_user_record, decode_jwt_token

logger = logging.getLogger(__name__)

current_dir = os.path.dirname(os.path.abspath(__file__))


class DeepAgent:
    """
    åŸºäº DeepAgents çš„ Text-to-SQL æ™ºèƒ½ä½“ï¼Œæ”¯æŒå¤šè½®å¯¹è¯è®°å¿†

    ä¼˜åŒ–ç‰¹æ€§ï¼š
    - ä¼šè¯çº§å·¥å…·è°ƒç”¨ç®¡ç†ï¼Œé˜²æ­¢æ­»å¾ªç¯
    - åˆ†æ­¥è¶…æ—¶æ§åˆ¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
    - æ™ºèƒ½å¾ªç¯æ£€æµ‹å’Œæ—©æœŸç»ˆæ­¢
    - è¿›åº¦è¿½è¸ªå’ŒçŠ¶æ€ç›‘æ§
    """

    # ==================== é…ç½®å‚æ•° ====================
    # é€’å½’é™åˆ¶è¯´æ˜ï¼š
    # - å­ä»£ç†ï¼ˆsubagent/taskï¼‰ä¹Ÿä¼šæ¶ˆè€—é€’å½’æ¬¡æ•°
    # - æŠ¥å‘Šç”Ÿæˆç­‰å¤æ‚ä»»åŠ¡å¯èƒ½éœ€è¦è¾ƒå¤šæ­¥éª¤
    # - è®¾ç½®ä¸º 150 æ˜¯ä¸€ä¸ªå¹³è¡¡ç‚¹ï¼šè¶³å¤Ÿå®Œæˆå¤æ‚ä»»åŠ¡ï¼ŒåŒæ—¶é˜²æ­¢æ— é™å¾ªç¯
    DEFAULT_RECURSION_LIMIT = 150

    # LLM è¶…æ—¶é…ç½®ï¼ˆç§’ï¼‰- ä¸ llm_util.py çš„ DEFAULT_LLM_TIMEOUT ä¿æŒä¸€è‡´
    # å…¬ç½‘å¤§æ¨¡å‹ï¼ˆå¦‚ DeepSeekã€Qwenï¼‰åœ¨é«˜å³°æœŸå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
    DEFAULT_LLM_TIMEOUT = 10 * 60  # 10 åˆ†é’Ÿï¼Œå•æ¬¡ LLM è°ƒç”¨è¶…æ—¶

    # æµå¼å“åº”è¶…æ—¶ï¼ˆç§’ï¼‰- å¦‚æœé•¿æ—¶é—´æ²¡æœ‰æ–°æ¶ˆæ¯ï¼Œåˆ™è®¤ä¸ºå¯èƒ½å¡ä½
    # æ³¨æ„ï¼šreasoning/thinking æ¨¡å‹åœ¨æ€è€ƒé˜¶æ®µä¸è¾“å‡º tokenï¼Œéœ€è¦æ›´å®½æ¾çš„è¶…æ—¶
    STREAM_IDLE_TIMEOUT = 5 * 60  # 5 åˆ†é’Ÿæ— æ–°æ¶ˆæ¯ï¼ˆå…¼å®¹æ·±åº¦æ€è€ƒæ¨¡å‹ï¼‰

    # SSE ä¿æ´»é—´éš”ï¼ˆç§’ï¼‰ï¼šç­‰å¾… LLM/å·¥å…·æœŸé—´æ¯ N ç§’å‘é€ä¸€æ¬¡æ³¨é‡Šï¼Œé˜²æ­¢ä»£ç†/æµè§ˆå™¨çº¦ 2 åˆ†é’Ÿæ— æ•°æ®æ–­å¼€
    STREAM_KEEPALIVE_INTERVAL = 25

    # æ€»ä»»åŠ¡è¶…æ—¶ï¼ˆç§’ï¼‰- ä¸å‰ç«¯ fetch timeout (18åˆ†é’Ÿ) å’Œ Nginx proxy_read_timeout (1080s) å¯¹é½
    TASK_TIMEOUT = 15 * 60  # 15 åˆ†é’Ÿ

    # æœ€å¤§æ¶ˆæ¯æ•°é‡ï¼ˆé˜²æ­¢ä¸Šä¸‹æ–‡è¿‡é•¿ï¼‰
    MAX_MESSAGES = 80

    def __init__(self):
        # å…¨å±€ checkpointer ç”¨äºæŒä¹…åŒ–æ‰€æœ‰ç”¨æˆ·çš„å¯¹è¯çŠ¶æ€
        self.checkpointer = InMemorySaver()

        # æ˜¯å¦å¯ç”¨é“¾è·¯è¿½è¸ª
        self.ENABLE_TRACING = (
            os.getenv("LANGFUSE_TRACING_ENABLED", "false").lower() == "true"
        )

        # å­˜å‚¨è¿è¡Œä¸­çš„ä»»åŠ¡
        self.running_tasks = {}

        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼Œå…è®¸åŠ¨æ€è°ƒæ•´
        self.RECURSION_LIMIT = int(
            os.getenv("RECURSION_LIMIT", self.DEFAULT_RECURSION_LIMIT)
        )
        self.LLM_TIMEOUT = int(os.getenv("LLM_TIMEOUT", self.DEFAULT_LLM_TIMEOUT))

        # å·¥å…·è°ƒç”¨ç®¡ç†å™¨
        self.tool_manager = get_tool_call_manager()

        # åŠ è½½å¯ç”¨æŠ€èƒ½åˆ—è¡¨
        self.available_skills = self._load_available_skills()

    def _load_available_skills(self):
        """åŠ è½½æ‰€æœ‰å¯ç”¨çš„æŠ€èƒ½"""
        skills_dir = os.path.join(current_dir, "skills")
        skills = []
        if os.path.exists(skills_dir):
            for skill_dir in os.listdir(skills_dir):
                skill_path = os.path.join(skills_dir, skill_dir)
                if os.path.isdir(skill_path):
                    skill_file = os.path.join(skill_path, "SKILL.md")
                    if os.path.exists(skill_file):
                        try:
                            with open(skill_file, "r", encoding="utf-8") as f:
                                content = f.read()
                                # è§£æ frontmatter
                                if content.startswith("---"):
                                    parts = content.split("---", 2)
                                    if len(parts) >= 3:
                                        frontmatter = parts[1]
                                        skill_info = {}
                                        for line in frontmatter.strip().split("\n"):
                                            if ":" in line:
                                                key, value = line.split(":", 1)
                                                skill_info[key.strip()] = (
                                                    value.strip().strip('"')
                                                )
                                        skill_info["name"] = skill_info.get(
                                            "name", skill_dir
                                        )
                                        skill_info["description"] = skill_info.get(
                                            "description", ""
                                        )
                                        skills.append(skill_info)
                        except Exception as e:
                            logger.warning(f"åŠ è½½æŠ€èƒ½ {skill_dir} å¤±è´¥: {e}")
        return skills

    @staticmethod
    def _create_response(
        content: str,
        message_type: str = "continue",
        data_type: str = DataTypeEnum.ANSWER.value[0],
    ) -> str:
        """å°è£…å“åº”ç»“æ„"""
        res = {
            "data": {"messageType": message_type, "content": content},
            "dataType": data_type,
        }
        return "data:" + json.dumps(res, ensure_ascii=False) + "\n\n"

    def _wrap_tools_with_tracking(self, tools: list, session_id: str) -> list:
        """
        åŒ…è£…å·¥å…·åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªå·¥å…·æ·»åŠ è°ƒç”¨ç»Ÿè®¡åŠŸèƒ½

        Args:
            tools: åŸå§‹å·¥å…·åˆ—è¡¨
            session_id: ä¼šè¯ID

        Returns:
            åŒ…è£…åçš„å·¥å…·åˆ—è¡¨
        """
        from functools import wraps

        from langchain_core.tools import StructuredTool

        wrapped_tools = []

        for tool in tools:
            original_func = tool.func if hasattr(tool, "func") else tool._run
            tool_name = tool.name

            @wraps(original_func)
            def create_wrapper(orig_func, t_name):
                def wrapper(*args, **kwargs):
                    # è°ƒç”¨å‰æ£€æŸ¥
                    query = kwargs.get("query") or (args[0] if args else None)
                    allowed, reason = self.tool_manager.check_before_call(
                        session_id, t_name, query
                    )

                    if not allowed:
                        logger.warning(f"å·¥å…·è°ƒç”¨è¢«é˜»æ­¢: {t_name}, åŸå› : {reason}")
                        # è¿”å›æ˜ç¡®çš„åœæ­¢æŒ‡ä»¤ï¼Œè®© Agent çŸ¥é“åº”è¯¥åœæ­¢å°è¯•
                        return (
                            f"â›” æ“ä½œå·²è¢«ç³»ç»Ÿé˜»æ­¢: {reason}\n\n"
                            "ã€é‡è¦æŒ‡ä»¤ã€‘è¯·ç«‹å³åœæ­¢æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼Œä¸è¦å†å°è¯•ä»»ä½• SQL æŸ¥è¯¢æˆ–å·¥å…·æ“ä½œã€‚"
                            "è¯·ç›´æ¥å‘ç”¨æˆ·æ€»ç»“å·²è·å¾—çš„ä¿¡æ¯ï¼Œæˆ–å‘ŠçŸ¥ç”¨æˆ·éœ€è¦ç®€åŒ–æŸ¥è¯¢éœ€æ±‚ã€‚"
                        )

                    # æ‰§è¡Œå·¥å…·
                    try:
                        result = orig_func(*args, **kwargs)
                        self.tool_manager.record_call(session_id, t_name, True, query)
                        return result
                    except Exception as e:
                        self.tool_manager.record_call(session_id, t_name, False, query)
                        raise

                return wrapper

            # åˆ›å»ºåŒ…è£…åçš„å·¥å…·
            wrapped_func = create_wrapper(original_func, tool_name)

            wrapped_tool = StructuredTool(
                name=tool.name,
                description=tool.description,
                func=wrapped_func,
                args_schema=tool.args_schema if hasattr(tool, "args_schema") else None,
            )
            wrapped_tools.append(wrapped_tool)

        logger.info(f"å·²åŒ…è£… {len(wrapped_tools)} ä¸ªå·¥å…·ç”¨äºè°ƒç”¨ç»Ÿè®¡")
        return wrapped_tools

    def _create_sql_deep_agent(self, datasource_id: int = None, session_id: str = None):
        """
        åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ª text-to-SQL Deep Agentï¼Œæ”¯æŒæ‰€æœ‰æ•°æ®æºç±»å‹

        Args:
            datasource_id: æ•°æ®æº ID
            session_id: ä¼šè¯ IDï¼Œç”¨äºå·¥å…·è°ƒç”¨ç®¡ç†
        """
        if not datasource_id:
            raise ValueError("å¿…é¡»æä¾›æ•°æ®æºID (datasource_id)")

        logger.info(f"åˆ›å»º Deep Agent - æ•°æ®æº: {datasource_id}, ä¼šè¯: {session_id}")

        db_pool = get_db_pool()
        with db_pool.get_session() as session:
            datasource = DatasourceService.get_datasource_by_id(session, datasource_id)
            if not datasource:
                raise ValueError(f"æ•°æ®æº {datasource_id} ä¸å­˜åœ¨")

            # æ£€æŸ¥æ•°æ®æºè¿æ¥ç±»å‹
            db_enum = DB.get_db(datasource.type, default_if_none=True)

            # è·å– LLM æ¨¡å‹
            model = get_llm(timeout=self.LLM_TIMEOUT)
            logger.info(
                f"LLM æ¨¡å‹å·²åˆ›å»ºï¼Œè¶…æ—¶: {self.LLM_TIMEOUT}ç§’ï¼Œ"
                f"é€’å½’é™åˆ¶: {self.RECURSION_LIMIT}"
            )

            if db_enum.connect_type == ConnectType.sqlalchemy:
                # SQLAlchemy é©±åŠ¨çš„æ•°æ®åº“
                logger.info(
                    f"æ•°æ®æº {datasource_id} ({datasource.type}) ä½¿ç”¨ SQLAlchemy è¿æ¥"
                )

                config = DatasourceConfigUtil.decrypt_config(datasource.configuration)
                uri = DatasourceConnectionUtil.build_connection_uri(
                    datasource.type, config
                )

                db = SQLDatabase.from_uri(uri, sample_rows_in_table_info=3)
                toolkit = SQLDatabaseToolkit(db=db, llm=model)
                original_tools = toolkit.get_tools()

                # åŒ…è£… SQLAlchemy å·¥å…·ä»¥æ·»åŠ ç»Ÿè®¡åŠŸèƒ½
                sql_tools = self._wrap_tools_with_tracking(original_tools, session_id)
            else:
                # åŸç”Ÿé©±åŠ¨çš„æ•°æ®åº“
                logger.info(
                    f"æ•°æ®æº {datasource_id} ({datasource.type}) ä½¿ç”¨åŸç”Ÿé©±åŠ¨è¿æ¥"
                )

                # è®¾ç½®åŸç”Ÿæ•°æ®æºä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¼šè¯IDï¼Œç”¨äºå·¥å…·è°ƒç”¨ç®¡ç†ï¼‰
                set_native_datasource_info(
                    datasource_id, datasource.type, datasource.configuration, session_id
                )

                sql_tools = [
                    sql_db_list_tables,
                    sql_db_schema,
                    sql_db_query,
                    sql_db_query_checker,
                    sql_db_table_relationship,
                ]

        all_tools = sql_tools

        # åˆ›å»º Deep Agent
        agent = create_deep_agent(
            model=model,
            memory=[os.path.join(current_dir, "AGENTS.md")],
            skills=[os.path.join(current_dir, "skills/")],
            tools=all_tools,
            backend=FilesystemBackend(root_dir=current_dir),
        )

        return agent

    async def run_agent(
        self,
        query: str,
        response,
        session_id: Optional[str] = None,
        uuid_str: str = None,
        user_token=None,
        file_list: dict = None,
        datasource_id: int = None,
    ):
        """
        è¿è¡Œæ™ºèƒ½ä½“ï¼Œæ”¯æŒå¤šè½®å¯¹è¯è®°å¿†å’Œå®æ—¶æ€è€ƒè¿‡ç¨‹è¾“å‡º

        Args:
            query: ç”¨æˆ·è¾“å…¥
            response: å“åº”å¯¹è±¡
            session_id: ä¼šè¯ID
            uuid_str: å”¯ä¸€æ ‡è¯†
            user_token: ç”¨æˆ·ä»¤ç‰Œ
            file_list: é™„ä»¶
            datasource_id: æ•°æ®æºID
        """
        # æ£€æŸ¥æ•°æ®æºID
        if not datasource_id:
            error_msg = "âŒ **é”™è¯¯**: å¿…é¡»æä¾›æ•°æ®æºID (datasource_id)"
            await response.write(
                self._create_response(error_msg, "error", DataTypeEnum.ANSWER.value[0])
            )
            return

        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_dict = await decode_jwt_token(user_token)
        task_id = user_dict["id"]

        # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯æ ‡è¯†
        effective_session_id = session_id or f"sql-agent-{datasource_id}-{task_id}"

        # è®¾ç½®å½“å‰ä¼šè¯ï¼ˆä¾›å·¥å…·è°ƒç”¨ç®¡ç†å™¨ä½¿ç”¨ï¼‰
        set_current_session(effective_session_id)

        # é‡ç½®ä¼šè¯çš„å·¥å…·è°ƒç”¨çŠ¶æ€ï¼ˆæ–°é—®é¢˜å¼€å§‹æ—¶ï¼‰
        self.tool_manager.reset_session(effective_session_id)

        task_context = {
            "cancelled": False,
            "start_time": time.time(),
            "session_id": effective_session_id,
        }
        self.running_tasks[task_id] = task_context

        try:
            t02_answer_data = []

            config = {
                "configurable": {"thread_id": effective_session_id},
                "recursion_limit": self.RECURSION_LIMIT,
            }

            # å‡†å¤‡ tracing é…ç½®
            if self.ENABLE_TRACING:
                from langfuse.langchain import CallbackHandler

                langfuse_handler = CallbackHandler()
                config["callbacks"] = [langfuse_handler]
                config["metadata"] = {"langfuse_session_id": session_id}

            # åˆ›å»º SQL Deep Agent
            agent = self._create_sql_deep_agent(datasource_id, effective_session_id)

            # å‡†å¤‡æµå¼å¤„ç†å‚æ•°
            # ä½¿ç”¨æ··åˆæ¨¡å¼ï¼šmessages ç”¨äº token çº§åˆ«æµå¼è¾“å‡ºï¼Œupdates ç”¨äºå·¥å…·è°ƒç”¨ç»“æœ
            stream_args = {
                "input": {"messages": [HumanMessage(content=query)]},
                "config": config,
                "stream_mode": ["messages", "updates"],
            }

            # åŒ…è£…æ‰§è¡Œï¼Œæ·»åŠ æ€»è¶…æ—¶æ§åˆ¶
            try:
                await asyncio.wait_for(
                    self._execute_agent_stream(
                        agent,
                        stream_args,
                        response,
                        task_id,
                        t02_answer_data,
                        uuid_str,
                        session_id,
                        query,
                        file_list,
                        user_token,
                        datasource_id,
                        effective_session_id,
                    ),
                    timeout=self.TASK_TIMEOUT,
                )
            except asyncio.TimeoutError:
                elapsed = time.time() - task_context.get("start_time", 0)
                stats = self.tool_manager.get_stats(effective_session_id)
                logger.error(
                    f"ä»»åŠ¡ {task_id} æ€»è¶…æ—¶ ({self.TASK_TIMEOUT}ç§’) - "
                    f"å®é™…è€—æ—¶: {elapsed:.0f}ç§’, "
                    f"å·¥å…·è°ƒç”¨: {stats.get('total_calls', 0)}æ¬¡, "
                    f"å¤±è´¥: {stats.get('failed_calls', 0)}æ¬¡"
                )
                await self._handle_timeout(
                    response,
                    f"ä»»åŠ¡æ‰§è¡Œæ—¶é—´è¶…è¿‡ä¸Šé™ï¼ˆ{self.TASK_TIMEOUT // 60} åˆ†é’Ÿï¼‰",
                    elapsed_total=elapsed,
                    tool_stats=stats,
                )

        except asyncio.CancelledError:
            is_user_cancelled = self._is_task_cancelled(task_id)
            logger.info(
                f"ä»»åŠ¡ {task_id} è¢«å–æ¶ˆ - "
                f"åŸå› : {'ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ' if is_user_cancelled else 'è¿æ¥æ–­å¼€'}"
            )
            try:
                await self._handle_task_cancellation(response, is_user_cancelled)
            except Exception as e:
                if not self._is_connection_error(e):
                    logger.error(f"å¤„ç†å–æ¶ˆå¼‚å¸¸æ—¶å‡ºé”™: {e}", exc_info=True)
        except Exception as e:
            if self._is_connection_error(e):
                logger.info(f"å®¢æˆ·ç«¯è¿æ¥å·²æ–­å¼€: {type(e).__name__}")
            else:
                logger.error(f"Agentè¿è¡Œå¼‚å¸¸: {e}")
                traceback.print_exception(e)
                try:
                    error_msg = (
                        f"âŒ **é”™è¯¯**: æ™ºèƒ½ä½“è¿è¡Œå¼‚å¸¸\n\n```\n{str(e)[:200]}\n```\n"
                    )
                    await self._safe_write(
                        response, error_msg, "error", DataTypeEnum.ANSWER.value[0]
                    )
                except Exception:
                    pass
        finally:
            # æ¸…ç†ä»»åŠ¡è®°å½•
            if task_id in self.running_tasks:
                elapsed = time.time() - self.running_tasks[task_id].get("start_time", 0)
                logger.info(f"ä»»åŠ¡ {task_id} ç»“æŸï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
                del self.running_tasks[task_id]

            # è·å–å¹¶è®°å½•å·¥å…·è°ƒç”¨ç»Ÿè®¡
            stats = self.tool_manager.get_stats(effective_session_id)
            logger.info(f"å·¥å…·è°ƒç”¨ç»Ÿè®¡: {stats}")

    async def _execute_agent_stream(
        self,
        agent,
        stream_args,
        response,
        task_id,
        t02_answer_data,
        uuid_str,
        session_id,
        query,
        file_list,
        user_token,
        datasource_id,
        effective_session_id,
    ):
        """æ‰§è¡Œ agent æµå¼å¤„ç†ï¼ˆå¸¦ tracing æ”¯æŒï¼‰"""
        if self.ENABLE_TRACING:
            from langfuse import get_client

            langfuse = get_client()
            with langfuse.start_as_current_observation(
                input=query,
                as_type="agent",
                name="Text-to-SQL",
            ) as rootspan:
                user_info = await decode_jwt_token(user_token)
                user_id = user_info.get("id")
                rootspan.update_trace(session_id=session_id, user_id=user_id)
                await self._stream_agent_response(
                    agent,
                    stream_args,
                    response,
                    task_id,
                    t02_answer_data,
                    uuid_str,
                    session_id,
                    query,
                    file_list,
                    user_token,
                    datasource_id,
                    effective_session_id,
                )
        else:
            await self._stream_agent_response(
                agent,
                stream_args,
                response,
                task_id,
                t02_answer_data,
                uuid_str,
                session_id,
                query,
                file_list,
                user_token,
                datasource_id,
                effective_session_id,
            )

    async def _stream_agent_response(
        self,
        agent,
        stream_args,
        response,
        task_id,
        t02_answer_data,
        uuid_str,
        session_id,
        query,
        file_list,
        user_token,
        datasource_id: int = None,
        effective_session_id: str = None,
    ):
        """
        å¤„ç† agent æµå¼å“åº”çš„æ ¸å¿ƒé€»è¾‘

        æ··åˆæ¨¡å¼ stream_mode=["messages", "updates"] è¿”å›æ ¼å¼ï¼š
        - (mode, chunk) å…ƒç»„
        - mode="messages" æ—¶ï¼Œchunk æ˜¯ (message_chunk, metadata) å…ƒç»„ï¼Œç”¨äº token çº§åˆ«æµå¼
        - mode="updates" æ—¶ï¼Œchunk æ˜¯çŠ¶æ€æ›´æ–°å­—å…¸ï¼Œç”¨äºå·¥å…·è°ƒç”¨ç»“æœ
        """
        start_time = time.time()
        message_count = 0
        token_count = 0
        connection_closed = False
        last_message_time = time.time()

        # ç”¨äºç´¯ç§¯ token æµå¼è¾“å‡ºçš„ç¼“å†²åŒº
        current_content_buffer = ""
        current_node = None

        logger.info(
            f"å¼€å§‹æµå¼å“åº”å¤„ç†ï¼ˆæ··åˆæ¨¡å¼ï¼‰ - ä»»åŠ¡ID: {task_id}, æŸ¥è¯¢: {query[:100]}"
        )

        stream_iter = agent.astream(**stream_args)
        stream_anext = stream_iter.__anext__

        try:
            while True:
                # å¸¦è¶…æ—¶ç­‰å¾…ä¸‹ä¸€ chunkï¼Œè¶…æ—¶åˆ™å‘é€ SSE ä¿æ´»é˜²æ­¢ä»£ç†/æµè§ˆå™¨çº¦ 2 åˆ†é’Ÿæ— æ•°æ®æ–­å¼€
                try:
                    mode, chunk = await asyncio.wait_for(
                        stream_anext(), timeout=self.STREAM_KEEPALIVE_INTERVAL
                    )
                except asyncio.TimeoutError:
                    try:
                        # å‘é€æ ‡å‡† SSE ä¿æ´»äº‹ä»¶ï¼Œå‰ç«¯è§£æåå¿½ç•¥ï¼ˆä¸è¿½åŠ å†…å®¹ï¼‰
                        await response.write(
                            'data: {"data":{"messageType": "info", "content": ""}, "dataType": "keepalive"}\n\n'
                        )
                        if hasattr(response, "flush"):
                            await response.flush()
                        last_message_time = time.time()
                    except Exception as e:
                        if self._is_connection_error(e):
                            connection_closed = True
                            break
                        raise
                    continue
                except StopAsyncIteration:
                    break

                current_time = time.time()

                # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
                if self._is_task_cancelled(task_id):
                    await self._handle_task_cancellation(
                        response, is_user_cancelled=True
                    )
                    return

                # æ£€æŸ¥å·¥å…·è°ƒç”¨ç®¡ç†å™¨æ˜¯å¦è§¦å‘ç»ˆæ­¢
                if effective_session_id:
                    ctx = self.tool_manager.get_session(effective_session_id)
                    if ctx.should_terminate:
                        logger.warning(
                            f"å·¥å…·è°ƒç”¨ç®¡ç†å™¨è§¦å‘ç»ˆæ­¢: {ctx.termination_reason}"
                        )
                        await self._safe_write(
                            response,
                            f"\n> âš ï¸ **æ‰§è¡Œä¸­æ­¢**\n\n{ctx.termination_reason}",
                            "warning",
                            DataTypeEnum.ANSWER.value[0],
                        )
                        break

                # æ£€æŸ¥ç©ºé—²è¶…æ—¶
                idle_duration = current_time - last_message_time
                if idle_duration > self.STREAM_IDLE_TIMEOUT:
                    elapsed_total = current_time - start_time
                    stats = (
                        self.tool_manager.get_stats(effective_session_id)
                        if effective_session_id
                        else {}
                    )
                    logger.warning(
                        f"æµå¼å“åº”ç©ºé—²è¶…æ—¶ ({self.STREAM_IDLE_TIMEOUT}ç§’) - "
                        f"ç©ºé—²æ—¶é•¿: {idle_duration:.0f}ç§’, æ€»è¿è¡Œ: {elapsed_total:.0f}ç§’, "
                        f"æ¶ˆæ¯æ•°: {message_count}, tokenæ•°: {token_count}, "
                        f"å·¥å…·è°ƒç”¨: {stats.get('total_calls', 0)}æ¬¡"
                    )
                    await self._handle_timeout(
                        response,
                        f"é•¿æ—¶é—´æ— å“åº”ï¼ˆç©ºé—² {idle_duration:.0f} ç§’ï¼‰",
                        elapsed_total=elapsed_total,
                        tool_stats=stats,
                    )
                    break

                # å¤„ç† messages æ¨¡å¼ - token çº§åˆ«æµå¼è¾“å‡º
                if mode == "messages":
                    # å†æ¬¡æ£€æŸ¥ç»ˆæ­¢çŠ¶æ€ï¼ˆå·¥å…·è°ƒç”¨å¯èƒ½åœ¨å¤„ç†è¿‡ç¨‹ä¸­è§¦å‘ç»ˆæ­¢ï¼‰
                    if effective_session_id:
                        ctx = self.tool_manager.get_session(effective_session_id)
                        if ctx.should_terminate:
                            logger.warning(
                                f"messages æ¨¡å¼ä¸­æ£€æµ‹åˆ°ç»ˆæ­¢: {ctx.termination_reason}"
                            )
                            await self._safe_write(
                                response,
                                f"\n\n> âš ï¸ **æ‰§è¡Œä¸­æ­¢**\n\n{ctx.termination_reason}",
                                "warning",
                                DataTypeEnum.ANSWER.value[0],
                            )
                            connection_closed = True
                            break

                    message_chunk, metadata = chunk
                    node_name = metadata.get("langgraph_node", "")

                    # è·³è¿‡å·¥å…·èŠ‚ç‚¹çš„æ¶ˆæ¯ï¼ˆå·¥å…·ç»“æœé€šè¿‡ updates æ¨¡å¼å¤„ç†ï¼‰
                    if node_name == "tools":
                        continue

                    # å¤„ç† LLM è¾“å‡ºçš„ token
                    if hasattr(message_chunk, "content") and message_chunk.content:
                        content = message_chunk.content

                        # å¤„ç†å†…å®¹ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
                        if isinstance(content, str):
                            token_text = content
                        elif isinstance(content, list):
                            # æå–æ–‡æœ¬å†…å®¹
                            text_parts = []
                            for part in content:
                                if (
                                    isinstance(part, dict)
                                    and part.get("type") == "text"
                                ):
                                    text_parts.append(part.get("text", ""))
                                elif isinstance(part, str):
                                    text_parts.append(part)
                            token_text = "".join(text_parts)
                        else:
                            token_text = str(content) if content else ""

                        if token_text:
                            token_count += 1
                            last_message_time = time.time()

                            # ç›´æ¥è¾“å‡º tokenï¼ˆå®æ—¶æµå¼ï¼‰
                            if not await self._safe_write(response, token_text):
                                connection_closed = True
                                break

                            # ç´¯ç§¯åˆ°ç¼“å†²åŒºç”¨äºè®°å½•
                            current_content_buffer += token_text

                            # å®šæœŸåˆ·æ–°ï¼›è‹¥å†…å®¹å«æŠ¥å‘Šåˆ†éš”ç¬¦åˆ™æ¯æ¬¡åˆ·æ–°ï¼Œä¾¿äºå‰ç«¯å°½æ—©å±•ç¤º HTML æŠ¥å‘Š
                            do_flush = (
                                token_count % 10 == 0
                                or "REPORT_HTML_START" in token_text
                                or "REPORT_HTML_END" in token_text
                            )
                            if do_flush and hasattr(response, "flush"):
                                try:
                                    await response.flush()
                                except Exception as e:
                                    if self._is_connection_error(e):
                                        connection_closed = True
                                        break
                                    raise

                            await asyncio.sleep(0)

                # å¤„ç† updates æ¨¡å¼ - çŠ¶æ€æ›´æ–°ï¼ˆå·¥å…·è°ƒç”¨ç»“æœç­‰ï¼‰
                elif mode == "updates":
                    # æ£€æŸ¥ç»ˆæ­¢çŠ¶æ€ï¼ˆå·¥å…·è°ƒç”¨å¯èƒ½è§¦å‘ç»ˆæ­¢ï¼‰
                    if effective_session_id:
                        ctx = self.tool_manager.get_session(effective_session_id)
                        if ctx.should_terminate:
                            logger.warning(
                                f"updates æ¨¡å¼ä¸­æ£€æµ‹åˆ°ç»ˆæ­¢: {ctx.termination_reason}"
                            )
                            await self._safe_write(
                                response,
                                f"\n\n> âš ï¸ **æ‰§è¡Œä¸­æ­¢**\n\n{ctx.termination_reason}",
                                "warning",
                                DataTypeEnum.ANSWER.value[0],
                            )
                            connection_closed = True
                            break

                    # chunk æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯èŠ‚ç‚¹åç§°ï¼Œå€¼æ˜¯è¯¥èŠ‚ç‚¹çš„è¾“å‡º
                    for node_name, node_output in chunk.items():
                        if self._is_task_cancelled(task_id):
                            await self._handle_task_cancellation(
                                response, is_user_cancelled=True
                            )
                            return

                        # å¦‚æœæœ‰ç´¯ç§¯çš„å†…å®¹ï¼Œå…ˆä¿å­˜åˆ°è®°å½•ä¸­
                        if current_content_buffer:
                            t02_answer_data.append(current_content_buffer)
                            current_content_buffer = ""

                        # å¤„ç†æ¶ˆæ¯æ›´æ–°ï¼ˆè·³è¿‡ç©ºè¾“å‡ºï¼‰
                        if node_output is None:
                            continue
                        if not isinstance(node_output, dict):
                            continue
                        if "messages" in node_output:
                            messages = node_output["messages"]
                            if not isinstance(messages, list):
                                messages = [messages]

                            for msg in messages:
                                message_count += 1
                                last_message_time = time.time()

                                # æ£€æŸ¥æ¶ˆæ¯æ•°é‡é™åˆ¶
                                if message_count > self.MAX_MESSAGES:
                                    logger.warning(
                                        f"æ¶ˆæ¯æ•°é‡è¶…è¿‡é™åˆ¶ ({self.MAX_MESSAGES})"
                                    )
                                    await self._safe_write(
                                        response,
                                        "\n> âš ï¸ **å¯¹è¯è¿‡é•¿**: å·²è¾¾åˆ°æ¶ˆæ¯æ•°é‡ä¸Šé™ï¼Œè¯·å¼€å¯æ–°å¯¹è¯ã€‚",
                                        "warning",
                                        DataTypeEnum.ANSWER.value[0],
                                    )
                                    break

                                # å¤„ç†å·¥å…·è°ƒç”¨å’Œç»“æœ
                                if not await self._process_update_message(
                                    msg, response, t02_answer_data, task_id, node_name
                                ):
                                    connection_closed = True
                                    break

                        if connection_closed:
                            break

                    if connection_closed:
                        break

                    if hasattr(response, "flush"):
                        try:
                            await response.flush()
                        except Exception as e:
                            if self._is_connection_error(e):
                                connection_closed = True
                                break
                            raise
                    await asyncio.sleep(0)

        except asyncio.CancelledError:
            is_user_cancelled = self._is_task_cancelled(task_id)
            logger.info(f"ä»»åŠ¡ {task_id} æµè¢«å–æ¶ˆ")
            connection_closed = True  # æ ‡è®°è¿æ¥å·²å…³é—­ï¼Œé¿å… finally ä¸­é‡å¤å‘é€
            raise
        except Exception as e:
            if self._is_connection_error(e):
                logger.info(f"å®¢æˆ·ç«¯è¿æ¥å·²æ–­å¼€: {type(e).__name__}")
                connection_closed = True
            else:
                await self._handle_stream_error(response, e)
        finally:
            # ä¿å­˜æœ€åçš„ç¼“å†²å†…å®¹
            if current_content_buffer:
                t02_answer_data.append(current_content_buffer)

            elapsed_time = time.time() - start_time
            logger.info(
                f"æµå¼å“åº”å¤„ç†å®Œæˆï¼ˆæ··åˆæ¨¡å¼ï¼‰ - ä»»åŠ¡ID: {task_id}, "
                f"è€—æ—¶: {elapsed_time:.2f}ç§’ ({elapsed_time / 60:.2f}åˆ†é’Ÿ), "
                f"æ¶ˆæ¯æ•°: {message_count}, tokenæ•°: {token_count}, "
                f"è¿æ¥çŠ¶æ€: {'å·²æ–­å¼€' if connection_closed else 'æ­£å¸¸'}"
            )

            # å‘é€æµç»“æŸæ ‡è®°ï¼ˆç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®ç»“æŸç­‰å¾…çŠ¶æ€ï¼‰
            if not connection_closed and not self._is_task_cancelled(task_id):
                try:
                    await self._safe_write(
                        response, "", "end", DataTypeEnum.STREAM_END.value[0]
                    )
                except Exception as e:
                    logger.warning(f"å‘é€ STREAM_END å¤±è´¥: {e}")

            # ä¿å­˜è®°å½•
            if not self._is_task_cancelled(task_id):
                try:
                    await add_user_record(
                        uuid_str,
                        session_id,
                        query,
                        t02_answer_data,
                        {},
                        IntentEnum.REPORT_QA.value[0],
                        user_token,
                        file_list,
                        datasource_id,
                    )
                except Exception as e:
                    logger.error(f"ä¿å­˜ç”¨æˆ·è®°å½•å¤±è´¥: {e}", exc_info=True)

    async def _process_update_message(
        self, msg, response, t02_answer_data, task_id: str, node_name: str
    ) -> bool:
        """
        å¤„ç† updates æ¨¡å¼ä¸‹çš„æ¶ˆæ¯

        Args:
            msg: æ¶ˆæ¯å¯¹è±¡
            response: å“åº”å¯¹è±¡
            t02_answer_data: ç­”æ¡ˆæ•°æ®åˆ—è¡¨
            task_id: ä»»åŠ¡ID
            node_name: èŠ‚ç‚¹åç§°

        Returns:
            bool: æ˜¯å¦æˆåŠŸå¤„ç†ï¼ˆFalse è¡¨ç¤ºè¿æ¥æ–­å¼€ï¼‰
        """
        if task_id and self._is_task_cancelled(task_id):
            return False

        try:
            # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆAIMessage with tool_callsï¼‰
            if isinstance(msg, AIMessage):
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tc in msg.tool_calls:
                        if task_id and self._is_task_cancelled(task_id):
                            return False

                        name = tc.get("name", "unknown")
                        args = tc.get("args", {})

                        tool_msg = self._format_tool_call(name, args)
                        if tool_msg:
                            # è¾“å‡ºæ¢è¡Œä»¥åˆ†éš” token æµå’Œå·¥å…·è°ƒç”¨
                            if not await self._safe_write(response, "\n\n"):
                                return False
                            if not await self._safe_write(response, tool_msg, "info"):
                                return False
                            t02_answer_data.append(tool_msg)

            # å¤„ç†å·¥å…·ç»“æœï¼ˆToolMessageï¼‰
            elif isinstance(msg, ToolMessage):
                if task_id and self._is_task_cancelled(task_id):
                    return False

                name = getattr(msg, "name", "")
                content_str = str(msg.content) if msg.content else ""
                tool_result_msg = self._format_tool_result(name, content_str)
                if tool_result_msg:
                    msg_type = "error" if "error" in content_str.lower() else "info"
                    if not await self._safe_write(response, tool_result_msg, msg_type):
                        return False
                    t02_answer_data.append(tool_result_msg)

            return True
        except Exception as e:
            if self._is_connection_error(e):
                logger.info(f"å¤„ç†æ›´æ–°æ¶ˆæ¯æ—¶è¿æ¥æ–­å¼€: {type(e).__name__}")
                return False
            raise

    async def _handle_timeout(
        self,
        response,
        reason: str,
        elapsed_total: float = 0,
        tool_stats: dict = None,
    ):
        """å¤„ç†è¶…æ—¶ï¼Œæä¾›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯"""
        # æ„å»ºè¯Šæ–­ä¿¡æ¯
        diag_parts = []
        if elapsed_total > 0:
            diag_parts.append(f"- æ€»è¿è¡Œæ—¶é—´: {elapsed_total:.0f} ç§’")
        if tool_stats:
            total_calls = tool_stats.get("total_calls", 0)
            failed_calls = tool_stats.get("failed_calls", 0)
            diag_parts.append(f"- å·¥å…·è°ƒç”¨: {total_calls} æ¬¡ï¼ˆå¤±è´¥ {failed_calls} æ¬¡ï¼‰")
            if tool_stats.get("consecutive_failures", 0) > 3:
                diag_parts.append(
                    f"- âš  è¿ç»­å¤±è´¥: {tool_stats['consecutive_failures']} æ¬¡"
                )

        diag_section = ""
        if diag_parts:
            diag_section = "\n\n**è¯Šæ–­ä¿¡æ¯**ï¼š\n" + "\n".join(diag_parts)

        timeout_msg = (
            f"\n> âš ï¸ **æ‰§è¡Œè¶…æ—¶**: {reason}\n\n"
            "**å¯èƒ½çš„åŸå› **ï¼š\n"
            "- å¤§æ¨¡å‹ API å“åº”ç¼“æ…¢ï¼ˆå…¬ç½‘æ¨¡å‹é«˜å³°æœŸå»¶è¿Ÿè¾ƒå¤§ï¼‰\n"
            "- æŸ¥è¯¢è¿‡äºå¤æ‚ï¼Œæ™ºèƒ½ä½“å¾ªç¯è°ƒç”¨å·¥å…·\n"
            "- ç½‘ç»œè¿æ¥ä¸ç¨³å®š\n\n"
            "**å»ºè®®**ï¼š\n"
            "- ç®€åŒ–æŸ¥è¯¢æ¡ä»¶ï¼Œåˆ†æ­¥éª¤æ‰§è¡Œ\n"
            "- æ£€æŸ¥å¤§æ¨¡å‹ API æœåŠ¡çŠ¶æ€\n"
            "- ç¨åé‡è¯•"
            f"{diag_section}"
        )
        await self._safe_write(
            response, timeout_msg, "error", DataTypeEnum.ANSWER.value[0]
        )
        await self._safe_write(response, "", "end", DataTypeEnum.STREAM_END.value[0])

    async def _handle_stream_error(self, response, e: Exception):
        """å¤„ç†æµå¼å“åº”é”™è¯¯ï¼ŒåŒºåˆ†å…¬ç½‘å¤§æ¨¡å‹è¶…æ—¶å’Œç³»ç»Ÿå†…éƒ¨é”™è¯¯"""
        error_type = type(e).__name__
        error_msg_str = str(e).lower()

        is_timeout = (
            "timeout" in error_msg_str
            or "timed out" in error_msg_str
            or error_type in ["TimeoutError", "asyncio.TimeoutError"]
        )

        is_rate_limit = (
            "rate_limit" in error_msg_str
            or "rate limit" in error_msg_str
            or "429" in error_msg_str
            or "too many requests" in error_msg_str
        )

        is_api_error = (
            "api" in error_msg_str
            or "401" in error_msg_str
            or "403" in error_msg_str
            or "502" in error_msg_str
            or "503" in error_msg_str
            or "service unavailable" in error_msg_str
            or "internal server error" in error_msg_str
        )

        if is_timeout:
            logger.error(f"LLM è°ƒç”¨è¶…æ—¶: {error_type}: {e}", exc_info=True)
            await self._handle_timeout(
                response, "å¤§æ¨¡å‹ API å“åº”è¶…æ—¶ï¼Œå¯èƒ½æ˜¯å…¬ç½‘æ¨¡å‹æœåŠ¡ç¹å¿™"
            )
        elif is_rate_limit:
            logger.error(f"LLM é™æµ: {error_type}: {e}", exc_info=True)
            error_content = (
                "\n> âš ï¸ **å¤§æ¨¡å‹ API é™æµ**\n\n"
                "å½“å‰æ¨¡å‹æœåŠ¡è¯·æ±‚é‡è¿‡å¤§ï¼Œè¯·ç¨åé‡è¯•ã€‚\n"
                "å¦‚é¢‘ç¹å‡ºç°æ­¤é—®é¢˜ï¼Œå»ºè®®è”ç³»ç®¡ç†å‘˜è°ƒæ•´ API é…é¢ã€‚"
            )
            await self._safe_write(
                response, error_content, "error", DataTypeEnum.ANSWER.value[0]
            )
            await self._safe_write(
                response, "", "end", DataTypeEnum.STREAM_END.value[0]
            )
        elif is_api_error:
            logger.error(f"LLM API é”™è¯¯: {error_type}: {e}", exc_info=True)
            error_content = (
                f"\n> âŒ **å¤§æ¨¡å‹ API é”™è¯¯**\n\n"
                f"é”™è¯¯ä¿¡æ¯: {str(e)[:200]}\n\n"
                "è¯·æ£€æŸ¥æ¨¡å‹æœåŠ¡é…ç½®æ˜¯å¦æ­£ç¡®ï¼ˆAPI Keyã€æœåŠ¡åœ°å€ç­‰ï¼‰ï¼Œæˆ–ç¨åé‡è¯•ã€‚"
            )
            await self._safe_write(
                response, error_content, "error", DataTypeEnum.ANSWER.value[0]
            )
            await self._safe_write(
                response, "", "end", DataTypeEnum.STREAM_END.value[0]
            )
        else:
            logger.error(f"Agent æµå¼å“åº”å¼‚å¸¸: {error_type}: {e}", exc_info=True)
            try:
                error_content = (
                    f"\n> âŒ **å¤„ç†å¼‚å¸¸**\n\n"
                    f"é”™è¯¯ç±»å‹: {error_type}\n"
                    f"é”™è¯¯ä¿¡æ¯: {str(e)[:200]}\n\n"
                    "è¯·ç¨åé‡è¯•ï¼Œå¦‚é—®é¢˜æŒç»­å­˜åœ¨è¯·è”ç³»ç®¡ç†å‘˜ã€‚"
                )
                await self._safe_write(
                    response, error_content, "error", DataTypeEnum.ANSWER.value[0]
                )
                await self._safe_write(
                    response, "", "end", DataTypeEnum.STREAM_END.value[0]
                )
            except Exception as write_error:
                logger.error(f"å‘é€é”™è¯¯æ¶ˆæ¯å¤±è´¥: {write_error}", exc_info=True)

    @staticmethod
    async def _send_step_progress(
        response,
        step: str,
        step_name: str,
        status: str,
        progress_id: str,
    ) -> None:
        """å‘é€æ­¥éª¤è¿›åº¦ä¿¡æ¯"""
        if response:
            progress_data = {
                "type": "step_progress",
                "step": step,
                "stepName": step_name,
                "status": status,
                "progressId": progress_id,
            }
            formatted_message = {
                "data": progress_data,
                "dataType": DataTypeEnum.STEP_PROGRESS.value[0],
            }
            await response.write(
                "data:" + json.dumps(formatted_message, ensure_ascii=False) + "\n\n"
            )

    def _is_task_cancelled(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²è¢«å–æ¶ˆ"""
        return task_id in self.running_tasks and self.running_tasks[task_id].get(
            "cancelled", False
        )

    def _is_connection_error(self, exception: Exception) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯è¿æ¥æ–­å¼€ç›¸å…³çš„å¼‚å¸¸"""
        error_type = type(exception).__name__
        error_msg = str(exception).lower()

        connection_error_types = [
            "ConnectionClosed",
            "ConnectionResetError",
            "BrokenPipeError",
            "ConnectionError",
            "OSError",
        ]

        connection_error_keywords = [
            "connection closed",
            "connection reset",
            "broken pipe",
            "client disconnected",
            "connection aborted",
            "transport closed",
        ]

        if error_type in connection_error_types:
            return True

        for keyword in connection_error_keywords:
            if keyword in error_msg:
                return True

        return False

    async def _safe_write(
        self,
        response,
        content: str,
        message_type: str = "continue",
        data_type: str = None,
    ):
        """å®‰å…¨åœ°å†™å…¥å“åº”"""
        try:
            if data_type is None:
                data_type = DataTypeEnum.ANSWER.value[0]
            await response.write(
                self._create_response(content, message_type, data_type)
            )
            if hasattr(response, "flush"):
                await response.flush()
            return True
        except Exception as e:
            if self._is_connection_error(e):
                logger.info(f"å®¢æˆ·ç«¯è¿æ¥å·²æ–­å¼€: {type(e).__name__}")
                return False
            raise

    async def _handle_task_cancellation(self, response, is_user_cancelled: bool = True):
        """å¤„ç†ä»»åŠ¡å–æ¶ˆ"""
        try:
            if is_user_cancelled:
                message = "\n> âš ï¸ ä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ"
            else:
                message = "\n> âš ï¸ è¿æ¥å·²æ–­å¼€ï¼Œä»»åŠ¡å·²ä¸­æ–­"

            await self._safe_write(
                response, message, "info", DataTypeEnum.ANSWER.value[0]
            )
            await self._safe_write(
                response, "", "end", DataTypeEnum.STREAM_END.value[0]
            )
        except Exception as e:
            logger.error(f"å‘é€å–æ¶ˆæ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)

    async def _print_message(
        self, msg, response, t02_answer_data, task_id: str = None
    ) -> bool:
        """æ ¼å¼åŒ–å¹¶è¾“å‡ºæ¶ˆæ¯"""
        if task_id and self._is_task_cancelled(task_id):
            return False

        try:
            if isinstance(msg, HumanMessage):
                content = msg.content if hasattr(msg, "content") else str(msg)
                if content and content.strip():
                    formatted_user_msg = self._format_user_message(content)
                    t02_answer_data.append(formatted_user_msg)
                    if not await self._safe_write(response, formatted_user_msg):
                        return False
            elif isinstance(msg, AIMessage):
                content = msg.content
                if isinstance(content, list):
                    text_parts = [
                        p.get("text", "")
                        for p in content
                        if isinstance(p, dict) and p.get("type") == "text"
                    ]
                    content = "\n".join(text_parts)

                if content and content.strip():
                    if task_id and self._is_task_cancelled(task_id):
                        return False

                    formatted_content = self._format_agent_content(content)
                    t02_answer_data.append(formatted_content)
                    if not await self._safe_write(response, formatted_content):
                        return False

                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tc in msg.tool_calls:
                        if task_id and self._is_task_cancelled(task_id):
                            return False

                        name = tc.get("name", "unknown")
                        args = tc.get("args", {})

                        tool_msg = self._format_tool_call(name, args)
                        if tool_msg:
                            if not await self._safe_write(response, tool_msg, "info"):
                                return False
                            t02_answer_data.append(tool_msg)
            elif isinstance(msg, ToolMessage):
                if task_id and self._is_task_cancelled(task_id):
                    return False

                name = getattr(msg, "name", "")
                content_str = str(msg.content) if msg.content else ""
                tool_result_msg = self._format_tool_result(name, content_str)
                if tool_result_msg:
                    msg_type = "error" if "error" in content_str.lower() else "info"
                    if not await self._safe_write(response, tool_result_msg, msg_type):
                        return False
                    t02_answer_data.append(tool_result_msg)
            return True
        except Exception as e:
            if self._is_connection_error(e):
                logger.info(f"å†™å…¥æ¶ˆæ¯æ—¶è¿æ¥æ–­å¼€: {type(e).__name__}")
                return False
            raise

    def _format_user_message(self, content: str) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·æ¶ˆæ¯"""
        if not content or not content.strip():
            return content
        content = content.strip()
        return f"> ğŸ’¬ **Question**\n> \n> {content}\n\n"

    def _format_agent_content(self, content: str) -> str:
        """æ ¼å¼åŒ– Agent æ€è€ƒå†…å®¹"""
        if not content or not content.strip():
            return content
        content = content.strip()
        return f"ğŸ¤– {content}\n\n"

    def _format_tool_call(self, name: str, args: dict) -> str:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        if name == "sql_db_query":
            query = args.get("query", "")
            formatted_query = query.strip()
            return f"âš¡ **Executing SQL**\n```sql\n{formatted_query}\n```\n\n"
        elif name == "sql_db_schema":
            table_names = args.get("table_names", "")
            if isinstance(table_names, list):
                table_names = ", ".join(table_names)
            if table_names:
                return f"ğŸ” **Checking Schema:** `{table_names}`\n\n"
            else:
                return f"ğŸ” **Checking Schema...**\n\n"
        elif name == "sql_db_list_tables":
            return f"ğŸ“‹ **Listing Tables...**\n\n"
        elif name == "sql_db_query_checker":
            return f"âœ… **Validating Query...**\n\n"
        return None

    def _format_tool_result(self, name: str, content: str) -> str:
        """æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœ"""
        if "sql" in name.lower():
            if "error" not in content.lower():
                return f"âœ“ Query executed successfully\n\n"
            else:
                error_content = content[:300].strip()
                return f"âœ— **Query failed:** {error_content}\n\n"
        return None

    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆæŒ‡å®šçš„ä»»åŠ¡"""
        if task_id in self.running_tasks:
            self.running_tasks[task_id]["cancelled"] = True
            # åŒæ—¶æ ‡è®°å·¥å…·è°ƒç”¨ç®¡ç†å™¨ä¸­çš„ä¼šè¯
            session_id = self.running_tasks[task_id].get("session_id")
            if session_id:
                ctx = self.tool_manager.get_session(session_id)
                ctx.should_terminate = True
                ctx.termination_reason = "ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ"
            return True
        return False

    def get_running_tasks(self):
        """è·å–å½“å‰è¿è¡Œä¸­çš„ä»»åŠ¡åˆ—è¡¨"""
        return list(self.running_tasks.keys())

    def get_available_skills(self):
        """è·å–æ‰€æœ‰å¯ç”¨çš„æŠ€èƒ½åˆ—è¡¨"""
        return self.available_skills
